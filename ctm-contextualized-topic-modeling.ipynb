{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30616,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/mortezaheidari/ctm-contextualized-topic-modeling?scriptVersionId=168601617\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# Combined TM combines the BoW with SBERT\n\n## Introduction: Unveiling the Significance of Topic Modeling\n\nTopic modeling, a powerful analytical tool, enables the extraction of meaningful patterns embedded within textual data. Its primary function is to facilitate the comprehension of large document collections by uncovering latent distributions of topics. This process simplifies the task of gaining insights into the content without the need to read each document individually. Through the lens of topic models, we can obtain a bird's eye view of the textual landscape, making it an invaluable asset for anyone dealing with extensive sets of documents.\n\n## Exploring the Functionality of Topic Models\n\nIn practical terms, topic models provide a structured approach to understanding the recurring themes present in a document collection. Rather than delving into individual documents one by one, topic modeling allows for the extraction of prevalent topics, offering a condensed summary of the overall content. By identifying patterns and themes that repeat across documents, this analytical technique transforms the daunting task of reviewing large datasets into a more manageable and insightful process. It becomes an indispensable aid for researchers, analysts, and anyone seeking a comprehensive overview of complex textual information.\n\n## Applications and Benefits of Topic Modeling\n\nBeyond the efficient summarization of document collections, topic modeling finds applications in various fields. It is widely used in natural language processing, information retrieval, and content recommendation systems. By revealing the underlying structures of textual data, topic models contribute to enhanced decision-making processes and foster a deeper understanding of the subject matter. Whether applied in academic research, business intelligence, or data analysis, topic modeling stands as a versatile tool that unlocks valuable insights from the vast realm of textual information.\n\n\n#### Ref1: Bianchi, F., Terragni, S., Hovy, D., Nozza, D., & Fersini, E. (2021). Cross-lingual Contextualized Topic Models with Zero-shot Learning. European Chapter of the Association for Computational Linguistics (EACL). https://arxiv.org/pdf/2004.07737/\n#### Ref2: https://github.com/MilaNLProc/contextualized-topic-models/tree/master","metadata":{}},{"cell_type":"markdown","source":"## Getting the data from Wikipedia for training and validation","metadata":{}},{"cell_type":"code","source":"%%capture\n!wget https://raw.githubusercontent.com/vinid/data/master/dbpedia_sample_abstract_20k_unprep.txt\n!wget https://raw.githubusercontent.com/vinid/data/master/dbpedia_sample_abstract_20k_prep.txt","metadata":{"execution":{"iopub.status.busy":"2024-03-24T20:16:16.63598Z","iopub.execute_input":"2024-03-24T20:16:16.636345Z","iopub.status.idle":"2024-03-24T20:16:19.930414Z","shell.execute_reply.started":"2024-03-24T20:16:16.636314Z","shell.execute_reply":"2024-03-24T20:16:19.928844Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"### Installing Contextualized Topic Models\n","metadata":{}},{"cell_type":"code","source":"%%capture\n!pip install contextualized-topic-models\n!pip install torch torchvision","metadata":{"execution":{"iopub.status.busy":"2024-03-24T20:16:19.933573Z","iopub.execute_input":"2024-03-24T20:16:19.933962Z","iopub.status.idle":"2024-03-24T20:16:54.890594Z","shell.execute_reply.started":"2024-03-24T20:16:19.933928Z","shell.execute_reply":"2024-03-24T20:16:54.888897Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"conda install -c conda-forge library_name","metadata":{"execution":{"iopub.status.busy":"2024-03-24T20:16:54.892353Z","iopub.execute_input":"2024-03-24T20:16:54.892704Z","iopub.status.idle":"2024-03-24T20:25:01.319186Z","shell.execute_reply.started":"2024-03-24T20:16:54.892672Z","shell.execute_reply":"2024-03-24T20:25:01.31782Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Retrieving notices: ...working... done\nCollecting package metadata (current_repodata.json): | WARNING conda.models.version:get_matcher(556): Using .* with relational operator is superfluous and deprecated and will be removed in a future version of conda. Your spec was 1.7.1.*, but conda is ignoring the .* and treating it as 1.7.1\ndone\nSolving environment: unsuccessful initial attempt using frozen solve. Retrying with flexible solve.\nCollecting package metadata (repodata.json): \\ WARNING conda.models.version:get_matcher(556): Using .* with relational operator is superfluous and deprecated and will be removed in a future version of conda. Your spec was 1.8.0.*, but conda is ignoring the .* and treating it as 1.8.0\nWARNING conda.models.version:get_matcher(556): Using .* with relational operator is superfluous and deprecated and will be removed in a future version of conda. Your spec was 1.6.0.*, but conda is ignoring the .* and treating it as 1.6.0\nWARNING conda.models.version:get_matcher(556): Using .* with relational operator is superfluous and deprecated and will be removed in a future version of conda. Your spec was 1.9.0.*, but conda is ignoring the .* and treating it as 1.9.0\ndone\nSolving environment: unsuccessful initial attempt using frozen solve. Retrying with flexible solve.\n\nPackagesNotFoundError: The following packages are not available from current channels:\n\n  - library_name\n\nCurrent channels:\n\n  - https://conda.anaconda.org/conda-forge/linux-64\n  - https://conda.anaconda.org/conda-forge/noarch\n  - https://conda.anaconda.org/rapidsai/linux-64\n  - https://conda.anaconda.org/rapidsai/noarch\n  - https://conda.anaconda.org/nvidia/linux-64\n  - https://conda.anaconda.org/nvidia/noarch\n  - https://repo.anaconda.com/pkgs/main/linux-64\n  - https://repo.anaconda.com/pkgs/main/noarch\n  - https://repo.anaconda.com/pkgs/r/linux-64\n  - https://repo.anaconda.com/pkgs/r/noarch\n\nTo search for alternate channels that may provide the conda package you're\nlooking for, navigate to\n\n    https://anaconda.org\n\nand use the search bar at the top of the page.\n\n\n\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Loading libraries:","metadata":{}},{"cell_type":"code","source":"from contextualized_topic_models.models.ctm import CombinedTM\nfrom contextualized_topic_models.utils.data_preparation import bert_embeddings_from_file, TopicModelDataPreparation\nfrom contextualized_topic_models.datasets.dataset import CTMDataset\nfrom contextualized_topic_models.evaluation.measures import CoherenceNPMI, InvertedRBO\nfrom gensim.corpora.dictionary import Dictionary\nfrom gensim.models import ldamodel \nimport os\nimport numpy as np\nimport pickle\nimport os\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"","metadata":{"execution":{"iopub.status.busy":"2024-03-24T20:25:01.322165Z","iopub.execute_input":"2024-03-24T20:25:01.322514Z","iopub.status.idle":"2024-03-24T20:25:24.661762Z","shell.execute_reply.started":"2024-03-24T20:25:01.322482Z","shell.execute_reply":"2024-03-24T20:25:24.660649Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Let's read our data files and store the documents as lists of strings","metadata":{}},{"cell_type":"code","source":"with open(\"dbpedia_sample_abstract_20k_prep.txt\", 'r') as fr_prep:\n  text_training_preprocessed = [line.strip() for line in fr_prep.readlines()]\n\nwith open(\"dbpedia_sample_abstract_20k_unprep.txt\", 'r') as fr_unprep:\n  text_training_not_preprocessed = [line.strip() for line in fr_unprep.readlines()]","metadata":{"execution":{"iopub.status.busy":"2024-03-24T20:25:24.663339Z","iopub.execute_input":"2024-03-24T20:25:24.664133Z","iopub.status.idle":"2024-03-24T20:25:24.723851Z","shell.execute_reply.started":"2024-03-24T20:25:24.664067Z","shell.execute_reply":"2024-03-24T20:25:24.722739Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"### NOTE: Make sure that the lenghts of the two lists of documents are the same and the index of a not preprocessed document corresponds to the index of the same preprocessed document.","metadata":{}},{"cell_type":"code","source":"assert len(text_training_preprocessed) == len(text_training_not_preprocessed)\n\nprint(text_training_not_preprocessed[0])\nprint(text_training_preprocessed[0])","metadata":{"execution":{"iopub.status.busy":"2024-03-24T20:25:24.725285Z","iopub.execute_input":"2024-03-24T20:25:24.726123Z","iopub.status.idle":"2024-03-24T20:25:24.732817Z","shell.execute_reply.started":"2024-03-24T20:25:24.72608Z","shell.execute_reply":"2024-03-24T20:25:24.73163Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"The Mid-Peninsula Highway is a proposed freeway across the Niagara Peninsula in the Canadian province of Ontario. Although plans for a highway connecting Hamilton to Fort Erie south of the Niagara Escarpment have surfaced for decades,it was not until The Niagara Frontier International Gateway Study was published by the Ministry\nmid peninsula highway proposed across peninsula canadian province ontario although highway connecting hamilton fort south international study published ministry\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Split the documents into training and testing","metadata":{}},{"cell_type":"code","source":"training_bow_documents = text_training_preprocessed[0:15000]\ntraining_contextual_document = text_training_not_preprocessed[0:15000]\n\ntesting_bow_documents = text_training_preprocessed[15000:]\ntesting_contextual_documents = text_training_not_preprocessed[15000:]","metadata":{"execution":{"iopub.status.busy":"2024-03-24T20:25:24.734268Z","iopub.execute_input":"2024-03-24T20:25:24.734579Z","iopub.status.idle":"2024-03-24T20:25:24.747291Z","shell.execute_reply.started":"2024-03-24T20:25:24.734552Z","shell.execute_reply":"2024-03-24T20:25:24.746254Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"## Creating the Training Dataset\n#### Let's pass our files with preprocess data to our TopicModelDataPreparation object. This object takes care of creating the bag of words for you and of obtaining the contextualized BERT representations of documents. This operation allows us to create our training dataset.","metadata":{}},{"cell_type":"code","source":"tp = TopicModelDataPreparation(\"bert-base-nli-mean-tokens\")\n# qt = TopicModelDataPreparation(\"all-mpnet-base-v2\") # TODO: you can change this data preparation \ntraining_dataset = tp.fit(training_contextual_document, training_bow_documents)","metadata":{"execution":{"iopub.status.busy":"2024-03-24T20:25:24.748703Z","iopub.execute_input":"2024-03-24T20:25:24.749138Z","iopub.status.idle":"2024-03-24T20:26:24.428173Z","shell.execute_reply.started":"2024-03-24T20:25:24.749101Z","shell.execute_reply":"2024-03-24T20:26:24.427269Z"},"trusted":true},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d65471fdb02544d38d2ed805feb4a71b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eb3d079bfebc4bb8883142831b7f4574"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/3.99k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8975edd003b54dcab0cf199d196b3a34"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dfaea17c26b846448ec9bdbdb2029665"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bdef03b189b9443c8c18d94c94aaed34"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/438M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3738f3d32cf243919f736c4cb53997fc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/399 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dd5830b1f7e340ba848b25a8999af1b4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2bb458ee8e2546f5b36cbe01658e9e11"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"96ade87a128b46ddb2c59b208160cdd1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d63dede25f00434faaef38a6b0ad7100"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b7196094727f43898dee2bcf0b856a4e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8e2efc622192415b8031e68a20450709"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/75 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4cfa7a03d77143f8a65fc23729198ead"}},"metadata":{}}]},{"cell_type":"markdown","source":"Why do we use the preprocessed text here? We need text without punctuation to build the bag of word. Also, we might want only to have the most frequent words inside the BoW. Too many words might not help.\n\nAnd what about the unpreprocessed text? We provide unpreprocessed text as the input for BERT (or the contextualized model of your choice) to let the model output more accurate document representations.","metadata":{}},{"cell_type":"code","source":"tp.vocab[:10]","metadata":{"execution":{"iopub.status.busy":"2024-03-24T20:26:24.429712Z","iopub.execute_input":"2024-03-24T20:26:24.430191Z","iopub.status.idle":"2024-03-24T20:26:24.438441Z","shell.execute_reply.started":"2024-03-24T20:26:24.430155Z","shell.execute_reply":"2024-03-24T20:26:24.437354Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"array(['abbreviated', 'academic', 'academy', 'access', 'according',\n       'achieved', 'acquired', 'acre', 'acres', 'across'], dtype=object)"},"metadata":{}}]},{"cell_type":"markdown","source":"### Combined Topic Model\nHere is how you can use the CombinedTM. This is a standard topic model that also uses contextualized embeddings. The good thing about CombinedTM is that it makes your topic much more coherent (see the paper https://arxiv.org/abs/2004.03974)\n#### ***  Combined TM combines the BoW with SBERT, a process that seems to increase the coherence of the predicted topics (https://arxiv.org/pdf/2004.03974.pdf). ","metadata":{}},{"cell_type":"code","source":"TOKENIZERS_PARALLELISM= False\nctm = CombinedTM(bow_size=len(tp.vocab), contextual_size=768, num_epochs=100, n_components=50)\nctm.fit(training_dataset)  \nprint(ctm.get_topics(2))","metadata":{"execution":{"iopub.status.busy":"2024-03-24T20:26:24.442952Z","iopub.execute_input":"2024-03-24T20:26:24.44335Z","iopub.status.idle":"2024-03-24T20:30:53.471737Z","shell.execute_reply.started":"2024-03-24T20:26:24.443314Z","shell.execute_reply":"2024-03-24T20:30:53.470438Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"Epoch: [100/100]\t Seen Samples: [1497600/1500000]\tTrain Loss: 134.99105241563586\tTime: 0:00:02.541938: : 100it [04:26,  2.67s/it]\n100%|██████████| 235/235 [00:02<00:00, 103.54it/s]","output_type":"stream"},{"name":"stdout","text":"defaultdict(<class 'list'>, {0: ['chinese', 'pinyin'], 1: ['film', 'best'], 2: ['west', 'within'], 3: ['new', 'york'], 4: ['rugby', 'union'], 5: ['chemical', 'given'], 6: ['league', 'club'], 7: ['women', 'world'], 8: ['states', 'united'], 9: ['government', 'responsible'], 10: ['town', 'parish'], 11: ['radio', 'fm'], 12: ['sierra', 'western'], 13: ['english', 'first'], 14: ['election', 'held'], 15: ['book', 'published'], 16: ['school', 'high'], 17: ['born', 'professional'], 18: ['brown', 'described'], 19: ['island', 'point'], 20: ['american', 'television'], 21: ['college', 'school'], 22: ['family', 'found'], 23: ['university', 'professor'], 24: ['french', 'son'], 25: ['iran', 'persian'], 26: ['park', 'state'], 27: ['research', 'journal'], 28: ['summer', 'metres'], 29: ['served', 'john'], 30: ['directed', 'film'], 31: ['album', 'band'], 32: ['historic', 'national'], 33: ['music', 'known'], 34: ['game', 'video'], 35: ['company', 'manufacturer'], 36: ['system', 'computer'], 37: ['member', 'politician'], 38: ['thus', 'associated'], 39: ['released', 'album'], 40: ['head', 'represented'], 41: ['year', 'race'], 42: ['church', 'building'], 43: ['czech', 'square'], 44: ['war', 'air'], 45: ['former', 'major'], 46: ['line', 'road'], 47: ['region', 'province'], 48: ['roman', 'greek'], 49: ['west', 'within']})\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Save the model for the future references","metadata":{}},{"cell_type":"code","source":"ctm.save(models_dir=\"./\")\n","metadata":{"execution":{"iopub.status.busy":"2024-03-24T20:30:53.473586Z","iopub.execute_input":"2024-03-24T20:30:53.474006Z","iopub.status.idle":"2024-03-24T20:30:53.566286Z","shell.execute_reply.started":"2024-03-24T20:30:53.473971Z","shell.execute_reply":"2024-03-24T20:30:53.565188Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/contextualized_topic_models/models/ctm.py:640: Warning: This is an experimental feature that we has not been fully tested. Refer to the following issue:https://github.com/MilaNLProc/contextualized-topic-models/issues/38\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Loading the Model from saved directory","metadata":{}},{"cell_type":"code","source":"ctm = CombinedTM(bow_size=len(tp.vocab), contextual_size=768, num_epochs=100, n_components=50)\nfile_dir = \"/kaggle/working/contextualized_topic_model_nc_50_tpm_0.0_tpv_0.98_hs_prodLDA_ac_(100, 100)_do_softplus_lr_0.2_mo_0.002_rp_0.99\"\nctm.load(\"/kaggle/working/contextualized_topic_model_nc_50_tpm_0.0_tpv_0.98_hs_prodLDA_ac_(100, 100)_do_softplus_lr_0.2_mo_0.002_rp_0.99/\",\n                                                                                                      epoch=99)","metadata":{"execution":{"iopub.status.busy":"2024-03-24T20:30:53.567544Z","iopub.execute_input":"2024-03-24T20:30:53.56785Z","iopub.status.idle":"2024-03-24T20:30:53.648461Z","shell.execute_reply.started":"2024-03-24T20:30:53.567823Z","shell.execute_reply":"2024-03-24T20:30:53.64725Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/contextualized_topic_models/models/ctm.py:669: Warning: This is an experimental feature that we has not been fully tested. Refer to the following issue:https://github.com/MilaNLProc/contextualized-topic-models/issues/38\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"markdown","source":"After training, now it is the time to look at our topics: we can use the function  get_topic_lists  to get the topics. It also accept a parameter that allows you to select how many words you want to see for each topic. If you look at the topics, you will see that they all make sense and are representative of a collection of documents that comes from Wikipedia (general knowledge).","metadata":{}},{"cell_type":"code","source":"ctm.get_topic_lists(5)","metadata":{"execution":{"iopub.status.busy":"2024-03-24T20:30:53.650342Z","iopub.execute_input":"2024-03-24T20:30:53.650726Z","iopub.status.idle":"2024-03-24T20:30:53.671096Z","shell.execute_reply.started":"2024-03-24T20:30:53.650693Z","shell.execute_reply":"2024-03-24T20:30:53.67012Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"[['chinese', 'pinyin', 'china', 'station', 'metro'],\n ['film', 'best', 'films', 'director', 'award'],\n ['west', 'within', 'south', 'approximately', 'east'],\n ['new', 'york', 'zealand', 'united', 'city'],\n ['rugby', 'union', 'australian', 'club', 'played'],\n ['chemical', 'given', 'either', 'space', 'defined'],\n ['league', 'club', 'season', 'football', 'stadium'],\n ['women', 'world', 'tennis', 'tournament', 'held'],\n ['states', 'united', 'list', 'county', 'state'],\n ['government', 'responsible', 'act', 'workers', 'police'],\n ['town', 'parish', 'small', 'village', 'located'],\n ['radio', 'fm', 'station', 'broadcasting', 'owned'],\n ['sierra', 'western', 'native', 'natural', 'southern'],\n ['english', 'first', 'made', 'right', 'class'],\n ['election', 'held', 'council', 'seats', 'member'],\n ['book', 'published', 'author', 'writer', 'books'],\n ['school', 'high', 'public', 'located', 'schools'],\n ['born', 'professional', 'world', 'player', 'russian'],\n ['brown', 'described', 'black', 'family', 'extinct'],\n ['island', 'point', 'land', 'mountain', 'named'],\n ['american', 'television', 'show', 'best', 'series'],\n ['college', 'school', 'education', 'private', 'educational'],\n ['family', 'found', 'mm', 'brown', 'white'],\n ['university', 'professor', 'studied', 'received', 'degree'],\n ['french', 'son', 'cross', 'duke', 'knight'],\n ['iran', 'persian', 'district', 'also', 'rural'],\n ['park', 'state', 'river', 'route', 'creek'],\n ['research', 'journal', 'reviewed', 'covering', 'academic'],\n ['summer', 'metres', 'gold', 'silver', 'competed'],\n ['served', 'john', 'wisconsin', 'american', 'born'],\n ['directed', 'film', 'written', 'produced', 'novel'],\n ['album', 'band', 'released', 'studio', 'rock'],\n ['historic', 'national', 'house', 'built', 'contributing'],\n ['music', 'known', 'composer', 'singer', 'musician'],\n ['game', 'video', 'developed', 'japan', 'series'],\n ['company', 'manufacturer', 'headquartered', 'founded', 'based'],\n ['system', 'computer', 'uses', 'standard', 'systems'],\n ['member', 'politician', 'party', 'norwegian', 'liberal'],\n ['thus', 'associated', 'less', 'belongs', 'either'],\n ['released', 'album', 'recorded', 'band', 'records'],\n ['head', 'represented', 'team', 'division', 'university'],\n ['year', 'race', 'held', 'car', 'first'],\n ['church', 'building', 'built', 'street', 'st'],\n ['czech', 'square', 'kilometres', 'region', 'covers'],\n ['war', 'air', 'force', 'royal', 'army'],\n ['former', 'major', 'american', 'played', 'league'],\n ['line', 'road', 'station', 'railway', 'england'],\n ['region', 'province', 'la', 'pronounced', 'municipality'],\n ['roman', 'greek', 'century', 'latin', 'catholic'],\n ['west', 'within', 'south', 'east', 'approximately']]"},"metadata":{}}]},{"cell_type":"markdown","source":"##  Now we are going to use the testset: we want to predict the topic for unseen documents.","metadata":{}},{"cell_type":"code","source":"# cear test set\ntesting_dataset = tp.fit(testing_contextual_documents, testing_bow_documents) # create dataset for the testset\npredictions = ctm.get_doc_topic_distribution(testing_dataset, n_samples=10)","metadata":{"execution":{"iopub.status.busy":"2024-03-24T20:30:53.672549Z","iopub.execute_input":"2024-03-24T20:30:53.672972Z","iopub.status.idle":"2024-03-24T20:31:14.359407Z","shell.execute_reply.started":"2024-03-24T20:30:53.672936Z","shell.execute_reply":"2024-03-24T20:31:14.358002Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/ipywidgets/widgets/widget.py:438: DeprecationWarning: The `ipykernel.comm.Comm` class has been deprecated. Please use the `comm` module instead.For creating comms, use the function `from comm import create_comm`.\n  self.comm = Comm(**args)\n/opt/conda/lib/python3.10/site-packages/ipywidgets/widgets/widget.py:438: DeprecationWarning: The `ipykernel.comm.Comm` class has been deprecated. Please use the `comm` module instead.For creating comms, use the function `from comm import create_comm`.\n  self.comm = Comm(**args)\n/opt/conda/lib/python3.10/site-packages/ipywidgets/widgets/widget.py:438: DeprecationWarning: The `ipykernel.comm.Comm` class has been deprecated. Please use the `comm` module instead.For creating comms, use the function `from comm import create_comm`.\n  self.comm = Comm(**args)\n/opt/conda/lib/python3.10/site-packages/ipywidgets/widgets/widget.py:438: DeprecationWarning: The `ipykernel.comm.Comm` class has been deprecated. Please use the `comm` module instead.For creating comms, use the function `from comm import create_comm`.\n  self.comm = Comm(**args)\n/opt/conda/lib/python3.10/site-packages/ipywidgets/widgets/widget.py:438: DeprecationWarning: The `ipykernel.comm.Comm` class has been deprecated. Please use the `comm` module instead.For creating comms, use the function `from comm import create_comm`.\n  self.comm = Comm(**args)\n/opt/conda/lib/python3.10/site-packages/ipywidgets/widgets/widget.py:438: DeprecationWarning: The `ipykernel.comm.Comm` class has been deprecated. Please use the `comm` module instead.For creating comms, use the function `from comm import create_comm`.\n  self.comm = Comm(**args)\n/opt/conda/lib/python3.10/site-packages/ipywidgets/widgets/widget.py:438: DeprecationWarning: The `ipykernel.comm.Comm` class has been deprecated. Please use the `comm` module instead.For creating comms, use the function `from comm import create_comm`.\n  self.comm = Comm(**args)\n/opt/conda/lib/python3.10/site-packages/ipywidgets/widgets/widget.py:438: DeprecationWarning: The `ipykernel.comm.Comm` class has been deprecated. Please use the `comm` module instead.For creating comms, use the function `from comm import create_comm`.\n  self.comm = Comm(**args)\n/opt/conda/lib/python3.10/site-packages/ipywidgets/widgets/widget.py:438: DeprecationWarning: The `ipykernel.comm.Comm` class has been deprecated. Please use the `comm` module instead.For creating comms, use the function `from comm import create_comm`.\n  self.comm = Comm(**args)\n/opt/conda/lib/python3.10/site-packages/ipywidgets/widgets/widget.py:438: DeprecationWarning: The `ipykernel.comm.Comm` class has been deprecated. Please use the `comm` module instead.For creating comms, use the function `from comm import create_comm`.\n  self.comm = Comm(**args)\n/opt/conda/lib/python3.10/site-packages/ipywidgets/widgets/widget.py:438: DeprecationWarning: The `ipykernel.comm.Comm` class has been deprecated. Please use the `comm` module instead.For creating comms, use the function `from comm import create_comm`.\n  self.comm = Comm(**args)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/25 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c713a026ce99453c9cf20e4bba1fb60a"}},"metadata":{}},{"name":"stderr","text":"100%|██████████| 79/79 [00:00<00:00, 87.31it/s] \n","output_type":"stream"}]},{"cell_type":"code","source":"print(testing_contextual_documents[15])\n\ntopic_index = np.argmax(predictions[15])\nctm.get_topic_lists(5)[topic_index]","metadata":{"execution":{"iopub.status.busy":"2024-03-24T20:31:14.361253Z","iopub.execute_input":"2024-03-24T20:31:14.361628Z","iopub.status.idle":"2024-03-24T20:31:14.377061Z","shell.execute_reply.started":"2024-03-24T20:31:14.361589Z","shell.execute_reply":"2024-03-24T20:31:14.375939Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Dhale (Arabic: الضالع‎‎ Aḍ Ḍāliʿ) province is one of the governorates of Yemen that have been created after the announcement of Yemeni unification. The population of the province accounted for (2.4%) of the total population of the Republic, and allocated administratively into (9) districts. Dali city is the centre of\n","output_type":"stream"},{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"['iran', 'persian', 'district', 'also', 'rural']"},"metadata":{}}]},{"cell_type":"code","source":"testing_dataset = tp.transform(text_for_contextual=testing_contextual_documents, text_for_bow=testing_bow_documents)\n\n# n_sample how many times to sample the distribution (see the doc)\nctm.get_doc_topic_distribution(testing_dataset, n_samples=20) # returns a (n_documents, n_topics) matrix with the topic distribution of each document\n","metadata":{"execution":{"iopub.status.busy":"2024-03-24T20:31:14.378803Z","iopub.execute_input":"2024-03-24T20:31:14.379951Z","iopub.status.idle":"2024-03-24T20:31:35.105135Z","shell.execute_reply.started":"2024-03-24T20:31:14.379906Z","shell.execute_reply":"2024-03-24T20:31:35.103943Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/ipywidgets/widgets/widget.py:438: DeprecationWarning: The `ipykernel.comm.Comm` class has been deprecated. Please use the `comm` module instead.For creating comms, use the function `from comm import create_comm`.\n  self.comm = Comm(**args)\n/opt/conda/lib/python3.10/site-packages/ipywidgets/widgets/widget.py:438: DeprecationWarning: The `ipykernel.comm.Comm` class has been deprecated. Please use the `comm` module instead.For creating comms, use the function `from comm import create_comm`.\n  self.comm = Comm(**args)\n/opt/conda/lib/python3.10/site-packages/ipywidgets/widgets/widget.py:438: DeprecationWarning: The `ipykernel.comm.Comm` class has been deprecated. Please use the `comm` module instead.For creating comms, use the function `from comm import create_comm`.\n  self.comm = Comm(**args)\n/opt/conda/lib/python3.10/site-packages/ipywidgets/widgets/widget.py:438: DeprecationWarning: The `ipykernel.comm.Comm` class has been deprecated. Please use the `comm` module instead.For creating comms, use the function `from comm import create_comm`.\n  self.comm = Comm(**args)\n/opt/conda/lib/python3.10/site-packages/ipywidgets/widgets/widget.py:438: DeprecationWarning: The `ipykernel.comm.Comm` class has been deprecated. Please use the `comm` module instead.For creating comms, use the function `from comm import create_comm`.\n  self.comm = Comm(**args)\n/opt/conda/lib/python3.10/site-packages/ipywidgets/widgets/widget.py:438: DeprecationWarning: The `ipykernel.comm.Comm` class has been deprecated. Please use the `comm` module instead.For creating comms, use the function `from comm import create_comm`.\n  self.comm = Comm(**args)\n/opt/conda/lib/python3.10/site-packages/ipywidgets/widgets/widget.py:438: DeprecationWarning: The `ipykernel.comm.Comm` class has been deprecated. Please use the `comm` module instead.For creating comms, use the function `from comm import create_comm`.\n  self.comm = Comm(**args)\n/opt/conda/lib/python3.10/site-packages/ipywidgets/widgets/widget.py:438: DeprecationWarning: The `ipykernel.comm.Comm` class has been deprecated. Please use the `comm` module instead.For creating comms, use the function `from comm import create_comm`.\n  self.comm = Comm(**args)\n/opt/conda/lib/python3.10/site-packages/ipywidgets/widgets/widget.py:438: DeprecationWarning: The `ipykernel.comm.Comm` class has been deprecated. Please use the `comm` module instead.For creating comms, use the function `from comm import create_comm`.\n  self.comm = Comm(**args)\n/opt/conda/lib/python3.10/site-packages/ipywidgets/widgets/widget.py:438: DeprecationWarning: The `ipykernel.comm.Comm` class has been deprecated. Please use the `comm` module instead.For creating comms, use the function `from comm import create_comm`.\n  self.comm = Comm(**args)\n/opt/conda/lib/python3.10/site-packages/ipywidgets/widgets/widget.py:438: DeprecationWarning: The `ipykernel.comm.Comm` class has been deprecated. Please use the `comm` module instead.For creating comms, use the function `from comm import create_comm`.\n  self.comm = Comm(**args)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/25 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6aac2fc63c3a49edb771b362208ea3a3"}},"metadata":{}},{"name":"stderr","text":"100%|██████████| 79/79 [00:00<00:00, 84.37it/s] \n","output_type":"stream"},{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"array([[0.00709262, 0.04367334, 0.00681018, ..., 0.00664655, 0.01195287,\n        0.00797423],\n       [0.00852594, 0.01326338, 0.00632783, ..., 0.0052157 , 0.01131592,\n        0.00638541],\n       [0.02267164, 0.01285871, 0.01620427, ..., 0.00576139, 0.00794419,\n        0.02032054],\n       ...,\n       [0.02139176, 0.03955531, 0.01359563, ..., 0.0753573 , 0.01213   ,\n        0.00568026],\n       [0.01651042, 0.01284623, 0.01245495, ..., 0.01171216, 0.01281426,\n        0.01155141],\n       [0.01543206, 0.01359013, 0.00893943, ..., 0.0089167 , 0.00657846,\n        0.00734071]], dtype=float32)"},"metadata":{}}]},{"cell_type":"markdown","source":"### Topic Predictions\nNow we can take a document and see which topic has been assigned to it. Results will obviously change with respect to the documents you are using. For example, let's predict the topic of the first preprocessed document that is talking about a peninsula.","metadata":{}},{"cell_type":"code","source":"topics_predictions = ctm.get_thetas(testing_dataset, n_samples=5) # get all the topic predictions","metadata":{"execution":{"iopub.status.busy":"2024-03-24T20:31:35.107123Z","iopub.execute_input":"2024-03-24T20:31:35.107615Z","iopub.status.idle":"2024-03-24T20:31:36.084097Z","shell.execute_reply.started":"2024-03-24T20:31:35.107572Z","shell.execute_reply":"2024-03-24T20:31:36.082777Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","text":"100%|██████████| 79/79 [00:00<00:00, 81.96it/s] \n","output_type":"stream"}]},{"cell_type":"code","source":"training_bow_documents[0] # see the text of our preprocessed document","metadata":{"execution":{"iopub.status.busy":"2024-03-24T20:31:36.086205Z","iopub.execute_input":"2024-03-24T20:31:36.08715Z","iopub.status.idle":"2024-03-24T20:31:36.094697Z","shell.execute_reply.started":"2024-03-24T20:31:36.087102Z","shell.execute_reply":"2024-03-24T20:31:36.09366Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"'mid peninsula highway proposed across peninsula canadian province ontario although highway connecting hamilton fort south international study published ministry'"},"metadata":{}}]},{"cell_type":"code","source":"topic_number = np.argmax(topics_predictions[0]) # get the topic id of the first document\nprint(ctm.get_topic_lists(5)[15])\nprint(ctm.get_topic_lists(5)[topic_number]) #and the topic should be about natural location/places/related things\n","metadata":{"execution":{"iopub.status.busy":"2024-03-24T20:31:36.096596Z","iopub.execute_input":"2024-03-24T20:31:36.096951Z","iopub.status.idle":"2024-03-24T20:31:36.118177Z","shell.execute_reply.started":"2024-03-24T20:31:36.096914Z","shell.execute_reply":"2024-03-24T20:31:36.117014Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"['book', 'published', 'author', 'writer', 'books']\n['university', 'professor', 'studied', 'received', 'degree']\n","output_type":"stream"}]},{"cell_type":"markdown","source":"","metadata":{}}]}